#!/usr/bin/env python3

from __future__ import annotations

import hashlib
import io
import marshal
import multiprocessing
import os
import pstats
import re
import shlex
import subprocess
import sys
import time
from collections import Counter
from dataclasses import astuple, dataclass, field
from datetime import timedelta
from functools import cached_property
from typing import Iterable, List, Optional, TypeVar, Union, cast

import click
import clickdc
from graphviz import Digraph
from tabulate import tabulate

###############################################################################

T = TypeVar("T")
V = TypeVar("V")


def md5sum(data: str) -> str:
    return hashlib.md5(data.encode("utf-8")).hexdigest()


def clamp(n, minn, maxn):
    return max(min(maxn, n), minn)


def dots_trim(v: str, width: int = 50) -> str:
    """if string is too long, trim it and add dots"""
    return v if len(v) <= width else (v[: width - 2] + "..")


def click_help():
    return click.help_option("-h", "--help")


def file_newer(a: str, b: str) -> bool:
    return (
        os.path.exists(a)
        and os.path.exists(b)
        and os.path.getctime(a) > os.path.getctime(b)
    )


def maybe_take_n(generator: Iterable[T], n: Optional[int]) -> Iterable[T]:
    """If n is ok, then take up to n elements"""
    if n and n > 0:
        return (a for _, a in zip(range(n), generator))
    else:
        return generator


def getdefault(e: list[T], idx: int, default: V = None) -> T | V:
    try:
        return e[idx]
    except (KeyError, IndexError):
        return default


def us2s(us: int) -> float:
    return us / 1000000


def fmtus(us: int) -> str:
    return f"{us:f}s"


###############################################################################


@dataclass
class RedGreenHue:
    elems: int

    def color(self, idx: int) -> Optional[str]:
        if self.elems == 0:
            return None
        val = int(0xFF * 2 / self.elems * idx)
        color = "#%02x%02x%02x" % (
            0xFF - val if 0 <= val < 0xFF else 0x00,
            val - 0xFF if 0xFF <= val else 0x00,
            0x00,
        )
        return color


@dataclass(frozen=True, order=True)
class FunctionKey:
    """To uniquely identify a function."""

    filename: str = "~"
    lineno: int = 0
    funcname: str = "~"

    def __str__(self):
        return f"{self.filename}:{self.lineno}({self.funcname})"


@dataclass
class Record:
    """Single line output from profiling information. Represents one instruction"""

    idx: int
    """Instruction number"""
    stamp_us: int
    """The timestamp as generated by EPOCHREALTIME"""
    cmd: str
    """$BASH_COMMAND"""
    level: int
    """${#BASH_SOURCE[@]}"""
    lineno: int
    """$LINENO"""
    source: str
    """$BASH_SOURCE, might be empty"""
    funcname: str
    """$BASH_FUNCNAME, might be empty"""
    trace: list[FunctionKey] = field(default_factory=list)
    """The call trace up to this function, from the bottom"""
    spent_us: int = -1
    """How long did the instruction take? Substraction of EPOCHREALTIME from the next instruction"""


class Records(List[Record]):
    """An array of records"""

    @property
    def sum_spent_us(self):
        return sum(x.spent_us for x in self)


@dataclass
class CmdStats:
    cmd: str = ""
    callcount: int = 0
    totaltime: int = 0


@dataclass
class CallgraphNode:
    """Single node in the callgraph tree"""

    function: FunctionKey = field(default_factory=FunctionKey)
    """An index to the function to unique identify the node"""
    callcount: int = 0
    """How many times this function was called from the parent?"""
    recursivecallcount: int = 0
    """How many times this function was called where the parent is itself?"""
    inlinetime: int = 0
    """How much time was spent in this node excluding subcalls"""
    childtime: int = 0
    """How much time was spent in this node only in subcalls"""
    children: dict[FunctionKey, CallgraphNode] = field(default_factory=dict)
    """functions called by this function"""
    cmdstats: dict[str, CmdStats] = field(default_factory=dict)
    """The commands executed by the function"""

    def add_record(self, r: Record):
        s = self.cmdstats.setdefault(r.cmd, CmdStats(r.cmd))
        s.callcount += 1
        s.totaltime += r.spent_us

    @property
    def totaltime(self):
        return self.inlinetime + self.childtime

    def merge(self, o: CallgraphNode):
        assert self.function == o.function
        self.callcount += o.callcount
        self.recursivecallcount += o.recursivecallcount
        self.inlinetime += o.inlinetime
        self.childtime += o.childtime
        for k, v in o.cmdstats.items():
            s = self.cmdstats.setdefault(k, CmdStats(k))
            s.callcount += v.callcount
            s.totaltime += v.totaltime
        for k, v in o.children.items():
            self.children.setdefault(k, CallgraphNode(k)).merge(v)


@dataclass
class Pstatsnocallers:
    """Statistics for pstats python module"""

    callcount: int = 0
    primitivecallcount: int = 0
    inlinetime: float = 0
    totaltime: float = 0


@dataclass
class Pstats(Pstatsnocallers):
    """Statistics for pstats python module"""

    callers: dict[FunctionKey, Pstatsnocallers] = field(default_factory=dict)


@dataclass
class AnalyzeArgs:
    """Command line arguments"""

    showanalyzetimes: Optional[bool] = clickdc.option()
    linelimit: Optional[int] = clickdc.option(
        help="From the input file, parse only that many lines from the top. This is used to reduce the numebr of analyzed lines for testing"
    )
    dotcallgraph: Optional[str] = clickdc.option(
        "--dot",
        help="Output file for dot callgraph file. Use for example `xdot <file>` to view.",
    )
    dotcallgraphlimit: int = clickdc.option(
        "--dotlimit",
        default=0,
        show_default=True,
        help="""
        When generating dot callgraph, limit the number of children of each point to max this number.
        Use this settings for big callgraphs where you do not see anything.
        """,
    )
    filterfunction: Optional[str] = clickdc.option(
        help="Only filter execution time of this particular function. Usefull for analysis of a single bash function execution"
    )
    pstats: Optional[str] = clickdc.option(
        help="TODO: Generate python pstats file just like python cProfile file"
    )
    dotfunction: Optional[str] = clickdc.option(
        help="""
            The callgraph is generated with functions matching given regex as roots.
            Implies --filterfunction
            """,
    )
    dotcmds: Optional[bool] = clickdc.option(help="Add commands to dot graph nodes")
    profilefile: Optional[io.TextIOBase] = clickdc.argument(
        type=click.File(errors="replace", lazy=True), required=False
    )


@dataclass
class RecordsSpentInterface:
    records: Records = field(default_factory=Records)
    spent: int = 0

    def add_record(self, rr: Record):
        self.records.append(rr)
        self.spent += rr.spent_us

    def get_example(self):
        cmdcnt = Counter(r.cmd for r in self.records)
        most_common_cmd: str = cmdcnt.most_common(1)[0][0]
        r: Record = next(r for r in self.records if r.cmd == most_common_cmd)
        return f"{r.source or '~'}:{r.lineno}"


@dataclass
class FunctionData(RecordsSpentInterface):
    """Accumulated data about a single function"""

    calls: int = 0

    def add(self, rr: Record, called: bool):
        self.add_record(rr)
        self.calls += called


@dataclass
class Timeit:
    """Measure time of a section"""

    name: str = ""
    start: float = 0
    duration: float = 0

    def __enter__(self):
        self.start = time.time()

    def __exit__(self, *_):
        self.duration = time.time() - self.start
        if self.name:
            self.print()

    def print(self):
        print(f"{self.name} took {timedelta(seconds=self.duration)} seconds")


@dataclass
class CommandData(RecordsSpentInterface):
    """Accumulated data about a single command"""

    callers: Counter[str] = field(default_factory=Counter)

    def add(self, rr: Record):
        self.add_record(rr)
        self.callers.update([rr.funcname])


@dataclass
class LineProcessor:
    """Processes lines from input file.
    Stores cached compile patterns.
    Exists to be multiprocessing-parallelized.
    Synchronize with profiling bash script.
    """

    linergx: re.Pattern
    filterfunction_rgx: Optional[re.Pattern]

    def process_line(self, data: tuple[int, str]) -> Optional[Record]:
        lineno, line = data
        if self.linergx.match(line):
            # Fix shlex.split not able to parse $'\''
            line = line.replace(r"\'", "")
            try:
                arr = shlex.split(line)
            except Exception as e:
                print("ERROR: lineno:", lineno, " line:", repr(line), e)
                return
            rr = Record(
                idx=lineno,
                stamp_us=int(arr[1]),
                cmd=arr[2],
                level=int(arr[3]),
                lineno=int(arr[4]),
                source=getdefault(arr, 5, ""),
                funcname=getdefault(arr, 6, ""),
            )
            return rr


@dataclass
class Analyzer:
    args: AnalyzeArgs
    records: list[Record] = field(default_factory=list)
    functions: dict[str, FunctionData] = field(default_factory=dict)
    commands: dict[str, CommandData] = field(default_factory=dict)

    def run(self):
        with self.timeit(f"Reading {self.args.profilefile}"):
            self.read()
        with self.timeit("Calculating traces and time spent"):
            self.infer_records_backtrace()
            self.calculate_records_spent_time()
        with self.timeit("Getting longest commands"):
            self.print_top_longest_commands()
        with self.timeit("Getting longest functions"):
            self.print_top_longest_functions()
        if self.args.dotcallgraph:
            with self.timeit("Generating dot callgraph"):
                self.extract_callgraph(self.args.dotcallgraph)
        if self.args.pstats:
            with self.timeit("Generting pstats file"):
                self.create_python_pstats_file(self.args.pstats)
        self.print_stats()

    def timeit(self, name: str):
        return Timeit(name if self.args.showanalyzetimes else "")

    @cached_property
    def execution_time_us(self):
        return self.records[-1].stamp_us - self.records[0].stamp_us

    def print_stats(self):
        print(
            f"Script executed in {timedelta(microseconds=self.execution_time_us)}us, {len(self.records)} instructions, {len(self.functions)} functions."
        )

    def read(self):
        # read the data
        lp = LineProcessor(
            linergx=re.compile(r"^# [0-9]+ .+$"),
            filterfunction_rgx=(
                re.compile(self.args.filterfunction)
                if self.args.filterfunction
                else None
            ),
        )
        with self.args.profilefile or sys.stdin as f:
            with multiprocessing.Pool() as pool:
                generator = maybe_take_n(enumerate(f), self.args.linelimit)
                self.records = [
                    x for x in pool.map(lp.process_line, generator) if x is not None
                ]
        self.records.sort(key=lambda x: x.idx)

    def infer_records_backtrace(self):
        curlevel = 1
        trace: list[FunctionKey] = []
        for rr in self.records:
            if rr.level > curlevel:
                trace.append(FunctionKey(rr.source, rr.lineno, rr.funcname))
            elif rr.level < curlevel:
                trace = trace[: -(curlevel - rr.level)]
            rr.trace = list(reversed(trace))
            curlevel = rr.level

    def calculate_records_spent_time(self):
        # convert absolute timestamp to relative
        for i in range(len(self.records) - 1):
            self.records[i].spent_us = (
                self.records[i + 1].stamp_us - self.records[i].stamp_us
            )
        self.records.pop()

    def print_top_longest_commands(self):
        self.commands = {}
        for rr in self.records:
            self.commands.setdefault(rr.cmd, CommandData()).add(rr)

        def get_top_caller(v: CommandData, i: int):
            if len(v.callers) <= i:
                return ""
            x = v.callers.most_common()[i]
            return f"{x[0]} {x[1]}"

        longest_commands: list[dict] = [
            dict(
                percent=v.spent / self.execution_time_us * 100,
                spent_us=f"{v.spent:_}",
                cmd=dots_trim(cmd),
                calls=len(v.records),
                spentPerCall=f"{v.spent / len(v.records):_}",
                topCaller1=get_top_caller(v, 0),
                topCaller2=get_top_caller(v, 1),
                topCaller3=get_top_caller(v, 2),
                example=v.get_example(),
            )
            for cmd, v in sorted(
                self.commands.items(),
                key=lambda x: -x[1].spent,
            )[:20]
        ]
        print(f"Top {len(longest_commands)} cummulatively longest commands:")
        print(tabulate(longest_commands, headers="keys"))
        print()

    def print_top_longest_functions(self):
        self.functions = {}
        prevfunctions: set[str] = set()
        for r in self.records:
            currentfunctions = set(t.funcname for t in r.trace)
            if r.trace:
                t = r.trace[0]
                called = False
                for f in currentfunctions:
                    if f not in prevfunctions:
                        called = True
                self.functions.setdefault(t.funcname, FunctionData()).add(r, called)
            prevfunctions = currentfunctions

        if not self.functions:
            return

        longest_functions: list[dict] = [
            dict(
                percent=v.spent / self.execution_time_us * 100,
                spent_us=f"{v.spent:_}",
                funcname=func,
                calls=v.calls,
                spentPerCall=v.spent / v.calls,
                instructions=len(v.records),
                instructionsPerCall=len(v.records) / v.calls,
                example=v.get_example(),
            )
            for func, v in sorted(
                self.functions.items(),
                key=lambda x: -x[1].spent,
            )[:20]
        ]
        print(f"Top {len(longest_functions)} cummulatively longest functions:")
        print(tabulate(longest_functions, headers="keys"))
        print()

    @cached_property
    def get_callgraph(self):
        # Create callgraph
        callgraph = CallgraphNode()
        prevlevel = 0
        for record in self.records:
            call = callgraph
            for t in reversed(record.trace):
                call.childtime += record.spent_us
                call = call.children.setdefault(t, CallgraphNode(t))
            if record.level > prevlevel:
                call.callcount += 1
                if len(record.trace) > 2 and record.trace[1] == record.trace[0]:
                    call.recursivecallcount += 1
            else:
                if call.inlinetime != 0:  # trickery!
                    call.add_record(record)
            call.inlinetime += record.spent_us
            prevlevel = record.level

        if self.args.dotfunction:
            # Filter dotfunction by merging the trees from the top node that matches the regex.
            dotfunctionrgx = re.compile(self.args.dotfunction)
            newcallgraph = CallgraphNode()

            def walk(node: CallgraphNode):
                if dotfunctionrgx.match(node.function.funcname):
                    newcallgraph.childtime += node.totaltime
                    newcallgraph.children.setdefault(
                        node.function, CallgraphNode(node.function)
                    ).merge(node)
                else:
                    for c in node.children.values():
                        walk(c)

            walk(callgraph)
            callgraph = newcallgraph

        return callgraph

    def extract_callgraph(self, outputfile: str):
        dot = Digraph()

        def callgraph_printer(
            parents: str, x: CallgraphNode, color: Optional[str] = None
        ):
            me = f"{parents}_{x.function.funcname}"
            dot.node(
                me,
                "\n".join(
                    [
                        f"{x.function.funcname}",
                        (
                            f"calls={x.callcount} total={x.totaltime:_}us percall={int(x.totaltime / (x.callcount or 1)):_}us"
                            if x.callcount
                            else f"total={x.totaltime:_}us"
                        ),
                        " ".join(
                            ([f"inline={x.inlinetime:_}us"] if x.inlinetime else [])
                            + ([f"childs={x.childtime:_}us"] if x.childtime else [])
                        ),
                    ]
                ),
                color=color,
            )
            nodechildren = list(x.children.values())
            children: list[Union[CallgraphNode, CmdStats]] = cast(
                list[Union[CallgraphNode, CmdStats]], nodechildren
            )
            if self.args.dotcmds:
                children.extend(list(x.cmdstats.values()))
            children = list(
                maybe_take_n(
                    sorted(children, key=lambda x: -x.totaltime),
                    self.args.dotcallgraphlimit,
                )
            )
            redgreenhue = RedGreenHue(len(children))
            for idx, child in enumerate(children):
                # print(val, inc, idx, len(x.childs), color)
                color = redgreenhue.color(idx)
                if isinstance(child, CallgraphNode):
                    dot.edge(
                        me,
                        f"{me}_{child.function.funcname}",
                        color=color,
                    )
                    callgraph_printer(me, child, color)
                else:
                    childname = f"{me}_{md5sum(child.cmd)}"
                    dot.edge(me, childname, color=color)
                    dot.node(
                        childname,
                        "\n".join(
                            [
                                repr(child.cmd),
                                f"calls={child.callcount} spent={child.totaltime:_}us",
                                f"percall={int(child.totaltime / child.callcount):_}us",
                            ]
                        ),
                        color=color,
                        shape="box",
                    )

        callgraph_printer("", self.get_callgraph)
        with open(outputfile, "w") as f:
            print(dot.source, file=f)

    def create_python_pstats_file(self, file: str):
        """
        https://github.com/python/cpython/blob/main/Lib/pstats.py#L160
        https://github.com/python/cpython/blob/main/Lib/cProfile.py#L63
        """
        # Extract function calls
        callgraph = self.get_callgraph
        statsroot: dict[FunctionKey, Pstats] = {}

        def fillstats(node: CallgraphNode):
            nodestats = statsroot.setdefault(node.function, Pstats())
            nodestats.callcount += node.callcount
            nodestats.primitivecallcount += node.callcount - node.recursivecallcount
            nodestats.totaltime += us2s(node.totaltime)
            nodestats.inlinetime += us2s(node.inlinetime)
            for child in node.children.values():
                fillstats(child)
                childstats = statsroot.setdefault(
                    child.function, Pstats()
                ).callers.setdefault(node.function, Pstatsnocallers())
                childstats.callcount += 1
                childstats.primitivecallcount += 1
                childstats.inlinetime += us2s(child.inlinetime)
                childstats.totaltime += us2s(child.totaltime)
                if child.function == node.function:
                    nodestats.totaltime -= us2s(child.totaltime)

        fillstats(callgraph)

        # Write pstats file
        def writer(what: Pstats):
            return (
                what.primitivecallcount,
                what.callcount,
                what.inlinetime,
                what.totaltime,
                {
                    astuple(key): (
                        val.primitivecallcount,
                        val.callcount,
                        val.inlinetime,
                        val.totaltime,
                    )
                    for key, val in what.callers.items()
                },
            )

        pstats = {astuple(key): writer(val) for key, val in statsroot.items()}
        with open(file, "wb") as f:
            marshal.dump(pstats, f)
        print(f"pstats file written to {file}")
        print()


###############################################################################


@click.group(
    help="""
Profile execution of bash scripts.
"""
)
@click_help()
def cli():
    pass


@cli.command(
    help="""
Generate profiling information of a given Bash script to PROFILEFILE.

The script has to run commands in the current execution environment.
Use `source ./script.sh` to run a script.
"""
)
@click.option("-o", "--output", type=click.File("w", lazy=True))
@click.argument("script")
@click_help()
def profile(output: Optional[io.FileIO], script: str):
    cmd = r"""
exec {_L_bash_profile_fd}>"$1"
shift
_L_bash_profile_debug() {
    printf "# %s %q %s %s %q %q\n" "${EPOCHREALTIME//[.,]}" "$BASH_COMMAND" "${#BASH_SOURCE[@]}" "${BASH_LINENO[0]}" "${BASH_SOURCE[1]:-}" "${FUNCNAME[1]:-}" >&"$_L_bash_profile_fd"
}
set -T
trap 'trap _L_bash_profile_debug DEBUG' DEBUG
eval "$@"
: END
"""
    profilefile = "/dev/stdout" if not output or output == sys.stdout else output.name
    cmd = ["bash", "-c", cmd, "bash", profilefile, script]
    print(f"PROFILING: {script} to {profilefile}", file=sys.stderr)
    subprocess.run(cmd)
    print(f"PROFING ENDED, output in {profilefile}", file=sys.stderr)


@cli.command(
    help="""
Analyze profiling information stored in PROFILEFILE.
    """
)
@click_help()
@clickdc.adddc("args", AnalyzeArgs)
def analyze(args: AnalyzeArgs):
    Analyzer(args).run()


@cli.command(help="print pstats data")
@click.option("-r", "--raw", is_flag=True, help="Just print marshal file content")
@click.argument("file", type=click.File("rb", lazy=True))
def showpstats(raw: bool, file: io.FileIO):
    if raw:

        def sortthem(x: dict):
            return sorted(x.items())

        def printit(prefix, key, val):
            print(
                f"{prefix}{key[0]}:{key[1]}({key[2]})  cc={val[0]} nc={val[1]} tt={val[2]:f} ct={val[3]:f}"
            )

        stats = marshal.load(file)
        for key, val in sortthem(stats):
            printit("", key, val)
            for key2, val2 in sortthem(val[4] or {}):
                printit(" ^ ", key2, val2)
    else:
        ps = pstats.Stats(file.name)
        sortby = "cumulative"
        ps.strip_dirs().sort_stats(sortby).print_stats()
        # plink around with this to get the results you need


###############################################################################

if __name__ == "__main__":
    cli.main()
