{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First run\n",
    "\n",
    "We present here a simple example to show the basic functionalities. It uses a random input tensor, more complex examples can be explored in the other [notebook](SWoTTeD_module_example.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from swotted import fastSWoTTeDModule, fastSWoTTeDTrainer, fastSWoTTeDDataset\n",
    "from swotted.loss_metrics import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from omegaconf import OmegaConf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first generate a random tensor. Note that the tensor can be replaced by an irregular tensor (list of tensors of size $N\\times T_k$ with $T_k$ that varies from one patient to the other)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 200  #: number of patients\n",
    "N = 5  #: number of medical events\n",
    "T = 10  #: length of time's stay\n",
    "#generation of a random tensor\n",
    "X=torch.bernoulli( torch.ones(K,N,T)*0.2 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now define the model. The configuration holds the main parameters of `SWoTTeD`.  It uses [OmegaConf](https://omegaconf.readthedocs.io) configuration to ease the use of the dictionaries.\n",
    "\n",
    "The SWoTTeD module is implemented as [PyTorch Lightning](https://lightning.ai/) module, and it has to be used with the corresponding trainer. Indeed, SWoTTeD optimisation problem is a not a classical supervised task and the optimization problem has to be set with the knowledge of the size of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "params = {}\n",
    "params[\"model\"] = {}\n",
    "params[\"model\"][\"non_succession\"] = 0.5\n",
    "params[\"model\"][\"sparsity\"] = 0.5\n",
    "params[\"model\"][\"rank\"] = 4  #: number of phenotypes to discover\n",
    "params[\"model\"][\"twl\"] = 3  #: length of time's window\n",
    "params[\"model\"][\"N\"] = N\n",
    "params[\"model\"][\"metric\"] = \"Bernoulli\"\n",
    "params[\"training\"] = {}\n",
    "params[\"training\"][\"batch_size\"] = 40\n",
    "params[\"training\"][\"nepochs\"] = 100\n",
    "params[\"training\"][\"lr\"] = 1e-2\n",
    "params[\"predict\"] = {}\n",
    "params[\"predict\"][\"nepochs\"] = 100\n",
    "params[\"predict\"][\"lr\"] = 1e-2\n",
    "\n",
    "config = OmegaConf.create(params)\n",
    "\n",
    "# define the model\n",
    "swotted = fastSWoTTeDModule(config)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    fastSWoTTeDDataset(X),\n",
    "    batch_size=params[\"training\"][\"batch_size\"],\n",
    "    shuffle=False,\n",
    "    collate_fn=lambda x: x,\n",
    ")\n",
    "\n",
    "# train the model\n",
    "trainer = fastSWoTTeDTrainer(\n",
    "    max_epochs=params[\"training\"][\"nepochs\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we run the training of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(model=swotted, train_dataloaders=train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we can explore the results: \n",
    "* visualize the extracted phenotypes\n",
    "* make reconstruction of input tensors\n",
    "* ... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the phenotypes\n",
    "Ph = swotted.Ph.flip(2).detach().numpy()\n",
    "for i in range(params[\"model\"][\"rank\"]):\n",
    "    plt.imshow(Ph[i], vmin=0, vmax=1, cmap=\"binary\",interpolation='none')\n",
    "    plt.ylabel(\"Drugs\")\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.title(\"Phenotype\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make decomposition with the train model: it projects the X on the phenotypes of the model\n",
    "# note that projection can be applied on new data. We use data from the training set for the sake\n",
    "# of simplicity\n",
    "id = 15\n",
    "W = swotted(X[id, :, :].unsqueeze(0))\n",
    "# Apply reconstruction\n",
    "Y = swotted.model.reconstruct(W,swotted.Ph)\n",
    "\n",
    "# Patient decomposition\n",
    "plt.subplot(211)\n",
    "plt.imshow(X[id].detach().numpy(), vmin=0, vmax=1, cmap=\"binary\",interpolation='none')\n",
    "plt.ylabel(\"Drugs\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.title(\"Input matrix\")\n",
    "plt.subplot(212)\n",
    "plt.imshow(Y[0].detach().numpy(), vmin=0, vmax=1, cmap=\"binary\",interpolation='none')\n",
    "plt.ylabel(\"Drugs\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.title(\"Pathway\")\n",
    "plt.title(\"reconstruction (not reordered)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
