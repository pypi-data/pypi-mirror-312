Metadata-Version: 2.1
Name: opfgym
Version: 0.3.2
Summary: Reinforcement Learning environments for learning the Optimal Power Flow
Author-email: Thomas Wolgast <thomas.wolgast@uni-oldenburg.de>
License: MIT License
        
        Copyright (c) 2022 Thomas Wolgast
        
        Permission is hereby granted, free of charge, to any person obtaining a copy
        of this software and associated documentation files (the "Software"), to deal
        in the Software without restriction, including without limitation the rights
        to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
        copies of the Software, and to permit persons to whom the Software is
        furnished to do so, subject to the following conditions:
        
        The above copyright notice and this permission notice shall be included in all
        copies or substantial portions of the Software.
        
        THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
        IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
        FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
        AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
        LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
        OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
        SOFTWARE.
        
Project-URL: Homepage, https://opf-gym.readthedocs.io
Project-URL: Repository, https://github.com/Digitalized-Energy-Systems/opfgym
Project-URL: Issues, https://github.com/Digitalized-Energy-Systems/opfgym/issues
Classifier: License :: OSI Approved :: MIT License
Classifier: Programming Language :: Python
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.12
Classifier: Programming Language :: Python :: 3.13
Classifier: Programming Language :: Python :: Implementation :: CPython
Classifier: Programming Language :: Python :: Implementation :: PyPy
Requires-Python: >=3.10
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: numpy>=1.22.4
Requires-Dist: scipy>=1.10.1
Requires-Dist: pandas>=1.3.5
Requires-Dist: matplotlib
Requires-Dist: lightsim2grid
Requires-Dist: pandapower>=2.13.1
Requires-Dist: simbench>=1.4.0
Requires-Dist: gymnasium>=0.29.0
Provides-Extra: test
Requires-Dist: pytest; extra == "test"
Requires-Dist: pytest-cov; extra == "test"
Provides-Extra: docs
Requires-Dist: sphinx; extra == "docs"
Requires-Dist: furo; extra == "docs"


[PyPi](https://pypi.org/project/opfgym/) 
| [Read the Docs](https://opf-gym.readthedocs.io)
| [Github](https://github.com/Digitalized-Energy-Systems/opfgym) 
| [mail](mailto:thomas.wolgast@uni-oldenburg.de)

![lifecycle](https://img.shields.io/badge/lifecycle-maturing-blue.svg)
[![MIT License](https://img.shields.io/badge/license-MIT-green.svg)](https://github.com/Digitalized-Energy-Systems/opfgym/blob/development/LICENSE)
[![Test OPF-gym](https://github.com/Digitalized-Energy-Systems/opfgym/actions/workflows/test-opfgym.yml/badge.svg)](https://github.com/Digitalized-Energy-Systems/opfgym/actions/workflows/test-opfgym.yml)

### General
A set of benchmark environments to solve the Optimal Power Flow (OPF) problem
with reinforcement learning (RL) algorithms. It is also easily possible to create custom OPF environments. 
All environments use the [gymnasium API](https://gymnasium.farama.org/index.html). 
The modelling of the power systems and the calculation of power flows happens with
[pandapower](https://pandapower.readthedocs.io/en/latest/index.html).
The benchmark power grids and time-series data of loads and generators are 
taken from [SimBench](https://simbench.de/en/).

Documentation can be found on https://opf-gym.readthedocs.io/en/latest/.

Warning: The whole repository is work-in-progress. Feel free to use the 
environments as benchmarks for your research. However, the environments can be 
expected to change slightly in the next months. The release of version 1.0 is 
planned for winter 2024. Afterward, the benchmarks will be kept as 
stable as possible. 

If you want to use the benchmark environments or the general framework to build 
own environments, please cite the following publication, where the framework is 
first mentioned (in an early stage): https://doi.org/10.1016/j.egyai.2024.100410



### Installation
Run `pip install opfgym` within some kind of virtual env.
For contributing, clone the repository and run `pip install -e .`.
Tested for python 3.10.


### Environments
Currently, five OPF benchmark environments are available. 

* EcoDispatch: Economic dispatch
* VoltageControl: Voltage Control with reactive power
* MaxRenewable: Maximize renewable feed-in
* QMarket: Reactive power market
* LoadShedding: Load shedding problem

Additionally, some 
example environments for more advanced features can be found in `opfgym/examples`. 

### Working With the Framework
All environments use the gymnasium API:
* Use `env.reset()` to start a new episode ([see gymnasium docs](https://gymnasium.farama.org/index.html))
* Use `env.step(action)` to apply an action to the environment ([see gymnasium docs](https://gymnasium.farama.org/index.html))
* Use `env.render()` to render the underlying power grid. For documentation of the usable keyword arguments, refer to the [pandapower documentation](https://pandapower.readthedocs.io/en/latest/plotting/matplotlib/simple_plot.html): 

On top, some additional OPF-specfic features are implemented: 
* Use `env.run_optimal_power_flow` to run an OPF on the current state. Returns True if successful, False otherwise. 
* Use `env.get_optimal_objective()` to return the optimal value of the objective function. Warning: Run `env.run_optimal_power_flow()` beforehand!
* Use `sum(env.calculate_objective())` to compute the value of the objective function in the current state. (Remove the `sum()` to get a vector representation)
* Use `env.get_current_actions()` to get the currently applied actions (e.g. generator setpoints). Warning: The actions are always scaled to range [0, 1] and not directly interpretable as power setpoints! 0 represents the minimum
possible setpoint, while 1 represents the maximum setpoint. 
* `env.is_state_valid()` to check if the current power grid state contains any 
constraint violations. 
* `env.is_optimal_state_valid()` to check if the power grid state contains any 
constraint violations after running the OPF. 
* Work-in-progress (TODO: `env.get_current_setpoints()`, `error_metrics` etc.)

### Contribution
Any kind of contribution is welcome! Feel free to create issues or merge 
requests. Also, additional benchmark environment are highly appreciated. For 
example, the `examples` environments could be refined to difficult but solvable
RL-OPF benchmarks. Here, it would be especially helpful to incorporate an OPF
solver that is more capable than the very limited pandapower OPF. For example, 
it should be able to deal with multi-stage problems, discrete actuators like
switches, and stochastic problems, which the pandapower OPF can't. 
For questions, feedback, collaboration, etc., contact thomas.wolgast@uni-oldenburg.de.
