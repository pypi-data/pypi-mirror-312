Metadata-Version: 2.1
Name: sotam
Version: 0.1.6
Summary: SOTAM-VLSTM: A next-generation, powerful LSTM-based framework for time-series forecasting and sequential data analysis. It automates preprocessing, enhances training with multi-GPU support, and provides insightful visualizations, making it perfect for applications in finance, healthcare, IoT, and beyond.
Home-page: https://github.com/anand-lab-172/STOAM
Author: Anandaram Ganapathi
Author-email: anandaram.ganapathi@gmail.com
License: MIT
Classifier: Programming Language :: Python :: 3
Classifier: License :: OSI Approved :: MIT License
Classifier: Operating System :: OS Independent
Requires-Python: >=3.6
Description-Content-Type: text/markdown

# SOTAM-VLSTM: Versatile Long Short-Term Memory

## Overview

**SOTAM-VLSTM** (State-of-the-Art Model - Versatile Long Short-Term Memory) is an enhanced LSTM architecture designed specifically for time-series prediction tasks. By integrating advanced features such as automated data preprocessing, training optimizations, dynamic hardware utilization, and robust evaluation metrics, SOTAM-VLSTM sets a new benchmark for efficiency and performance in time-series forecasting.

Its versatility makes it suitable for a wide range of real-world applications, from financial market analysis to anomaly detection in IoT systems. Whether you're a data scientist, researcher, or developer, SOTAM-VLSTM simplifies the workflow, improves accuracy, and significantly reduces training time.

**Key Features:**
- **Customizable LSTM architecture**: Choose the number of layers, units, and other hyperparameters.
- **Data preprocessing**: Automatic scaling of features using MinMaxScaler to improve model performance.
- **Training optimization**: Includes ModelCheckpoint and EarlyStopping to prevent overfitting and save time.
- **Dynamic GPU/CPU selection with MirroredStrategy**:  If GPUs are available, training is distributed across multiple GPUs; otherwise, it defaults to CPU for training.
- **Prediction-ready**: Seamlessly make predictions on new data.
- **Comprehensive evaluation**: Use multiple metrics like MAE, RMSE, MAPE, and MAD for performance assessment.
- **Interactive visualizations**: Plot training loss and predictions using Plotly for better insight into model performance.
- **Prediction-ready**: Easily make predictions on new data with pre-fitted scalers.

---

## Use Cases

**VLSTM** is perfect for time-series regression tasks. Some common use cases include:

- **Stock Price Prediction**: Predicting future stock prices based on historical market data.
- **Sales Forecasting**: Predicting future sales or demand for products in various industries.
- **Weather Forecasting**: Predicting weather conditions based on past data.
- **Energy Consumption Forecasting**: Estimating future energy usage based on historical consumption patterns.
- **Anomaly Detection**: Identifying unusual patterns in time-series data.
- **Healthcare Analytics** : Predicting patient vitals and tracking disease progression.
- **IoT and Smart Systems**: Enabling predictive maintenance using sensor data.
- **Traffic Flow Prediction**: Planning transportation infrastructure and optimizing traffic systems.
- **Social Media Analytics**: Forecasting user engagement trends for marketing campaigns.
- **Agriculture and Environment**: Improving crop yield prediction and monitoring environmental conditions.
- **Cybersecurity**: Detecting potential security breaches through time-series analysis of network logs.
- **Gaming Analytics**: Predicting user activity and in-game economic trends for better player engagement.

---
## Useful Links

- Git Repo: https://github.com/anand-lab-172/STOAM
- Developer Profile: https://www.linkedin.com/in/anandaramg
---

![VLSTM](https://github.com/anand-lab-172/STOAM/blob/main/vlstm_arch.png?raw=true)

## How to Use VLSTM

### 1. **Installation**
To install the required dependencies, run the following command:

```bash
pip install -r requirements.txt
```

### 2. **Preparing Data**
Your dataset should be in a Pandas DataFrame (df) format with:

* Features: Columns containing historical data (e.g., 'Open', 'High', 'Low', 'Close' for stock prices).
* Target: A column with the values you want to predict (e.g., 'Close' for stock price prediction).
Use the prepare_data() method to preprocess your data:

```bash
from sotam import VLSTM
df = pd.read_csv('filename.csv')
top_features = df.columns # I have take top correlating columns based on df.corr(), but you can also directly pass like this
vlstm = VLSTM(target='Close') # target is mandatory, pass your target feature in string (makesure you pass with no null values)
X, y = vlstm.prepare_data(df, features = top_features) # top_features: column names (vlstm.prepare_data() is not mandatory, everything is automated on backend)
```

### 3. **Training the Model**
Once the data is ready, train the model using the train() method:

```bash
history, y_test, y_pred, train_score, test_score = vlstm.train(df, features = top_features) # top_features: column names
```

### 4. **Evaluating the Model**
After training, evaluate the model's performance using various metrics such as MAE, RMSE, MAPE, and MAD:

```bash
vlstm.evaluate(y_test, y_pred) # get various evaluation metrics
```

### 5. **Making Predictions**
To make predictions on new data:

```bash
predictions = vlstm.predict(new_df, features = top_features) # top_features: column names
```

### 6. **Visualizing Results**
You can visualize training loss and the actual vs predicted values:

```bash
vlstm.plot_loss(history)
vlstm.prediction_plot(y_test, y_pred)
```

## Model Architecture

The VLSTM architecture consists of two LSTM layers followed by a Dense layer and Dropout for regularization. The network is highly customizable to meet the needs of different datasets and tasks. Here's a breakdown of the model layers:

1. LSTM Layer 1: This is a customizable layer with a user-defined number of units.
2. LSTM Layer 2: Another LSTM layer that can capture more complex time-series dependencies.
3. Dense Layer: A fully connected layer with a customizable number of units.
4. Dropout: Regularization layer to prevent overfitting by randomly dropping units during training.
5. Output Layer: The final Dense layer with a customizable activation function (linear for regression tasks).

## Comparison to Traditional LSTM

| **Feature**               | **SOTAM-VLSTM**                                                              | **Traditional LSTM**                                                      |
|---------------------------|-------------------------------------------------------------------------------|---------------------------------------------------------------------------|
| **Model Customization**   | Highly customizable: sequence length, number of layers, units, dropout, etc. | Limited customization, usually one or two LSTM layers with default configurations. |
| **Data Preprocessing**    | Automatic MinMax scaling of features and dynamic handling of the target feature. | Requires manual data preprocessing and scaling of features.              |
| **Training Optimization** | Includes ModelCheckpoint and EarlyStopping to improve training efficiency and prevent overfitting. | Usually lacks these optimizations, leading to potential overfitting or inefficient training. |
| **GPU/CPU Optimization**  |Uses **MirroredStrategy** for distributed training across multiple GPUs if available; defaults to CPU when no GPU is detected.| Often defaults to CPU with limited GPU support.                          |
| **Evaluation Metrics**    | Provides detailed metrics: MAE, MAPE, MAD for robust model evaluation.  | Often limited to basic metrics like MSE or accuracy.                     |
| **Prediction Readiness**  | Seamless transition for making predictions on new data with fitted scalers.   | Manual scaling required for prediction, making it less convenient.       |
| **Model Saving and Deployment** | Saves the best model automatically for deployment and inference.                  | Requires manual saving/loading of the model, less convenient for deployment. |
| **Training Time**         | ~30-50% faster due to optimizations                                          | Slower due to lack of optimizations.                                      |
| **Accuracy (RÂ² Score)**   | ~98-99%                                                                      | ~97-98%.                                                                  |
| **Ease of Use**           | High: Automates preprocessing, model saving/loading, hardware selection, and multi-GPU support. | Medium: Requires manual intervention for many steps.                      |


## Why VLSTM is Better than Traditional LSTM:
* Advanced Features: VLSTM automates many processes (e.g., data scaling, model saving/loading, and training optimizations), reducing the manual effort required to build and deploy models.
* Optimized for Real-World Use: With GPU/CPU optimization, callbacks, and a focus on saving the best model, VLSTM is designed for more complex, scalable, and efficient workflows.
* Better Evaluation and Visualization: VLSTM provides comprehensive evaluation metrics and powerful visualizations to track model performance, making it easier to interpret results.

## Conclusion
VLSTM (Versatile Long Short-Term Memory) is a more flexible, efficient, and scalable approach to time-series forecasting compared to traditional LSTM models. It is ideal for use in real-world applications where ease of deployment, training optimization, and model interpretability are important. By offering robust features like automatic data preprocessing, early stopping, model checkpointing, and dynamic GPU utilization, VLSTM provides significant advantages over basic LSTM architectures, especially in production environments.
