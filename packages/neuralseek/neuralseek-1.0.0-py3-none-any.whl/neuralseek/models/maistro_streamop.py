"""Code generated by Speakeasy (https://speakeasy.com). DO NOT EDIT."""

from __future__ import annotations
from neuralseek.types import BaseModel
import pydantic
from typing import List, Optional
from typing_extensions import Annotated, NotRequired, TypedDict


class MaistroStreamParamsTypedDict(TypedDict):
    name: NotRequired[str]
    r"""The parameter name"""
    value: NotRequired[str]
    r"""The parameter value"""


class MaistroStreamParams(BaseModel):
    name: Optional[str] = ""
    r"""The parameter name"""

    value: Optional[str] = ""
    r"""The parameter value"""


class MaistroStreamLastTurnTypedDict(TypedDict):
    input: NotRequired[str]
    r"""The user input"""
    response: NotRequired[str]
    r"""The system response.  Text strings only here."""


class MaistroStreamLastTurn(BaseModel):
    input: Optional[str] = ""
    r"""The user input"""

    response: Optional[str] = ""
    r"""The system response.  Text strings only here."""


class MaistroStreamOptionsTypedDict(TypedDict):
    r"""Override options"""

    llm: NotRequired[str]
    r"""Override the LLM load balancer and force seek to use a specific LLM.  Input the LLM code here.  You must have a valid model card set up on the configure tab for the code you input."""
    user_id: NotRequired[str]
    r"""Set the user_id. Useful and required if you have a corporate document filter set"""
    timeout: NotRequired[float]
    r"""Timeout in miliseconds. (optional)"""
    temperature_mod: NotRequired[float]
    r"""Shift the model's baseline temperature weighting by a percentage"""
    topp_mod: NotRequired[float]
    r"""Shift the model's baseline probability weighting by a percentage"""
    freqpenalty_mod: NotRequired[float]
    r"""Shift the model's baseline frequency penalty weighting by a percentage"""
    min_tokens: NotRequired[float]
    r"""Set the minimum tokens you  want the model to produce"""
    max_tokens: NotRequired[float]
    r"""Set the maximum tokens you  want the model to produce"""
    last_turn: NotRequired[List[MaistroStreamLastTurnTypedDict]]
    r"""lastTurn is a flexible object. It is backwards compatible with the original single turn object, as well as compatible with the Watson Assistant session history format."""
    return_variables: NotRequired[bool]
    r"""Return the final state of all variables in a dense object"""
    return_variables_expanded: NotRequired[bool]
    r"""Return the final state of all variables in the same format as the input params"""
    return_render: NotRequired[bool]
    r"""Return the midstate renders"""
    return_source: NotRequired[bool]
    r"""Return the source parts"""
    max_recursion: NotRequired[int]
    r"""The maximum number of recursive calls to Explore.  Use caution that you have not created an endless loop as you increase the maximum, as each Explore is charged."""


class MaistroStreamOptions(BaseModel):
    r"""Override options"""

    llm: Optional[str] = ""
    r"""Override the LLM load balancer and force seek to use a specific LLM.  Input the LLM code here.  You must have a valid model card set up on the configure tab for the code you input."""

    user_id: Optional[str] = ""
    r"""Set the user_id. Useful and required if you have a corporate document filter set"""

    timeout: Optional[float] = None
    r"""Timeout in miliseconds. (optional)"""

    temperature_mod: Annotated[
        Optional[float], pydantic.Field(alias="temperatureMod")
    ] = None
    r"""Shift the model's baseline temperature weighting by a percentage"""

    topp_mod: Annotated[Optional[float], pydantic.Field(alias="toppMod")] = None
    r"""Shift the model's baseline probability weighting by a percentage"""

    freqpenalty_mod: Annotated[
        Optional[float], pydantic.Field(alias="freqpenaltyMod")
    ] = None
    r"""Shift the model's baseline frequency penalty weighting by a percentage"""

    min_tokens: Annotated[Optional[float], pydantic.Field(alias="minTokens")] = None
    r"""Set the minimum tokens you  want the model to produce"""

    max_tokens: Annotated[Optional[float], pydantic.Field(alias="maxTokens")] = None
    r"""Set the maximum tokens you  want the model to produce"""

    last_turn: Annotated[
        Optional[List[MaistroStreamLastTurn]], pydantic.Field(alias="lastTurn")
    ] = None
    r"""lastTurn is a flexible object. It is backwards compatible with the original single turn object, as well as compatible with the Watson Assistant session history format."""

    return_variables: Annotated[
        Optional[bool], pydantic.Field(alias="returnVariables")
    ] = False
    r"""Return the final state of all variables in a dense object"""

    return_variables_expanded: Annotated[
        Optional[bool], pydantic.Field(alias="returnVariablesExpanded")
    ] = False
    r"""Return the final state of all variables in the same format as the input params"""

    return_render: Annotated[Optional[bool], pydantic.Field(alias="returnRender")] = (
        False
    )
    r"""Return the midstate renders"""

    return_source: Annotated[Optional[bool], pydantic.Field(alias="returnSource")] = (
        False
    )
    r"""Return the source parts"""

    max_recursion: Annotated[Optional[int], pydantic.Field(alias="maxRecursion")] = 10
    r"""The maximum number of recursive calls to Explore.  Use caution that you have not created an endless loop as you increase the maximum, as each Explore is charged."""


class MaistroStreamRequestBodyTypedDict(TypedDict):
    r"""The request object."""

    ntl: NotRequired[str]
    r"""The NTL script to evaluate.  Include either this or templateName - not both"""
    template_name: NotRequired[str]
    r"""The templateName to use. Include either this or input"""
    params: NotRequired[List[MaistroStreamParamsTypedDict]]
    r"""An array of parameters to use in evaluation of the NTL"""
    options: NotRequired[MaistroStreamOptionsTypedDict]
    r"""Override options"""


class MaistroStreamRequestBody(BaseModel):
    r"""The request object."""

    ntl: Optional[str] = ""
    r"""The NTL script to evaluate.  Include either this or templateName - not both"""

    template_name: Annotated[Optional[str], pydantic.Field(alias="templateName")] = ""
    r"""The templateName to use. Include either this or input"""

    params: Optional[List[MaistroStreamParams]] = None
    r"""An array of parameters to use in evaluation of the NTL"""

    options: Optional[MaistroStreamOptions] = None
    r"""Override options"""


class MaistroStreamVarsTypedDict(TypedDict):
    r"""The variable values"""


class MaistroStreamVars(BaseModel):
    r"""The variable values"""


class MaistroStreamRenderTypedDict(TypedDict):
    node: NotRequired[str]
    r"""The node type"""
    vars: NotRequired[MaistroStreamVarsTypedDict]
    r"""The variable values"""
    out: NotRequired[str]
    r"""The output"""
    chained: NotRequired[bool]
    r"""True if the step is chained"""


class MaistroStreamRender(BaseModel):
    node: Optional[str] = ""
    r"""The node type"""

    vars: Optional[MaistroStreamVars] = None
    r"""The variable values"""

    out: Optional[str] = ""
    r"""The output"""

    chained: Optional[bool] = None
    r"""True if the step is chained"""


class MaistroStreamVariablesTypedDict(TypedDict):
    r"""The returned variable."""


class MaistroStreamVariables(BaseModel):
    r"""The returned variable."""


class MaistroStreamVariablesExpandedTypedDict(TypedDict):
    name: NotRequired[str]
    r"""The variable name"""
    value: NotRequired[str]
    r"""The variable value"""


class MaistroStreamVariablesExpanded(BaseModel):
    name: Optional[str] = ""
    r"""The variable name"""

    value: Optional[str] = ""
    r"""The variable value"""


class DataTypedDict(TypedDict):
    answer: NotRequired[str]
    r"""The generated response"""
    source_parts: NotRequired[List[str]]
    render: NotRequired[List[MaistroStreamRenderTypedDict]]
    r"""The steps used to render the result."""
    variables: NotRequired[MaistroStreamVariablesTypedDict]
    r"""The returned variable."""
    variables_expanded: NotRequired[List[MaistroStreamVariablesExpandedTypedDict]]
    r"""The returned variable, in the format of the input params"""


class Data(BaseModel):
    answer: Optional[str] = ""
    r"""The generated response"""

    source_parts: Annotated[
        Optional[List[str]], pydantic.Field(alias="sourceParts")
    ] = None

    render: Optional[List[MaistroStreamRender]] = None
    r"""The steps used to render the result."""

    variables: Optional[MaistroStreamVariables] = None
    r"""The returned variable."""

    variables_expanded: Annotated[
        Optional[List[MaistroStreamVariablesExpanded]],
        pydantic.Field(alias="variablesExpanded"),
    ] = None
    r"""The returned variable, in the format of the input params"""


class MaistroStreamResponseBodyTypedDict(TypedDict):
    r"""Success"""

    data: DataTypedDict


class MaistroStreamResponseBody(BaseModel):
    r"""Success"""

    data: Data
